{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "i6097snn6aPF"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import os\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LA3ouOIf6aPM"
   },
   "outputs": [],
   "source": [
    "def read_file(file_name, conf):\n",
    "    sentences_labeled= []\n",
    "    file_data= (open(os.getcwd()+'\\Data\\\\'+ conf + '\\\\'+ file_name+'.txt', encoding='UTF-8')).readlines()\n",
    "    print(file_name+ \" tweets count: \"+ str(len(file_data)))\n",
    "    sentences_labeled= [(sentence.strip(), file_name) for sentence in file_data]\n",
    "    return sentences_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7jUYxsag6aPQ"
   },
   "outputs": [],
   "source": [
    "# Binary feature vector  (bir kelimenin dökümanda var olup olmadığıyla ilgilenir (döküman= burada tweetlerimiz oluyor))\n",
    "# Bag of words metodunu kullanarak tweetleri şekillendiriyoruz\n",
    "def binary_features(tweet_words):\n",
    "    my_dict= {word:True for word in tweet_words}\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1115,
     "status": "ok",
     "timestamp": 1527161451107,
     "user": {
      "displayName": "Emrah Tema",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102019531740135725055"
     },
     "user_tz": -180
    },
    "id": "zl4CS4vQ6aPT",
    "outputId": "59b0659e-f767-47ad-aca0-00398afaf678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mutlu tweets count: 987\n",
      "kiz tweets count: 906\n",
      "uzul tweets count: 899\n",
      "kork tweets count: 274\n",
      "Sentences labeled:\n",
      "[('\\ufeffkendi rengarenk yün çorap al şimdi onlar ben birkaç gün mutlu eder', 'mutlu'), ('günaydın mutlu sabahla', 'mutlu'), ('öyle mutlu çaydanlık gülümse az önce', 'mutlu'), ('saye gelin kız kardeş gibi parla mutlu', 'mutlu'), ('hoca matematik soru ödev ver bir kaç soru yap çok mutlu as', 'mutlu')]\n",
      "\n",
      "Sentences labeled and converted to dictionary:\n",
      "[({'kendi': True, 'rengarenk': True, 'yün': True, 'çorap': True, 'al': True, 'şimdi': True, 'onlar': True, 'ben': True, 'birkaç': True, 'gün': True, 'mutlu': True, 'eder': True}, 'mutlu'), ({'günaydın': True, 'mutlu': True, 'sabahla': True}, 'mutlu'), ({'öyle': True, 'mutlu': True, 'çaydanlık': True, 'gülümse': True, 'az': True, 'önce': True}, 'mutlu'), ({'saye': True, 'gelin': True, 'kız': True, 'kardeş': True, 'gibi': True, 'parla': True, 'mutlu': True}, 'mutlu'), ({'hoca': True, 'matematik': True, 'soru': True, 'ödev': True, 'ver': True, 'bir': True, 'kaç': True, 'yap': True, 'çok': True, 'mutlu': True, 'as': True}, 'mutlu')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Veri setimizde;\n",
    "# Conf1 tweetlerin orjinal hallerini barındırır, sadece kelime düzeltme işlemleri yapılmıştır\n",
    "# Conf2 Tweetlerin kelimeleri düzeltilmiş, noktalama işaretlerinden arındırılmış ve kökleri alınmış hallerini barındırır\n",
    "#     ve aynı zamanda değil kelimesinin anlamı güçlendirilmiş olup olumsuz kelimeler özel olarak işaretlenmiştir\n",
    "# Conf3 Conf1'in noktalama işaretleri olmayan hali\n",
    "# Conf4 Conf3'ün deyimler içermeyen hali, sadece normal tweetler\n",
    "# Conf5 Conf2'nin deyimler içermeyen hali, sadece normal tweetler\n",
    "\n",
    "# Tweetlerin her bir Conf içerisindeki hali farklı işlemler görmüştür. Her bir veri setinin başarı oranı şekline göre\n",
    "#     değişecektir. Amaç bunu gözlemlemektir ancak burada sadece Conf2'yi kullanacağız\n",
    "config= 'Conf2'\n",
    "\n",
    "mutlu= read_file(\"mutlu\", config) # mutluluk içeren tweetler\n",
    "kiz= read_file(\"kiz\", config) # kızgınlık içeren tweetler\n",
    "uzul= read_file(\"uzul\", config) # üzüntü içeren tweetler\n",
    "kork= read_file(\"kork\", config) # korku içeren tweetler\n",
    "\n",
    "tokenizer=RegexpTokenizer(\"[\\w']+\")\n",
    "binary_feature_mutlu= [(binary_features(tokenizer.tokenize(tweet)), cat) for (tweet,cat) in mutlu]\n",
    "binary_feature_kiz= [(binary_features(tokenizer.tokenize(tweet)), cat) for (tweet,cat) in kiz]\n",
    "binary_feature_uzul= [(binary_features(tokenizer.tokenize(tweet)), cat) for (tweet,cat) in uzul]\n",
    "binary_feature_kork= [(binary_features(tokenizer.tokenize(tweet)), cat) for (tweet,cat) in kork]\n",
    "\n",
    "labeled_data= mutlu + kiz + uzul + kork\n",
    "print(\"Sentences labeled:\")\n",
    "print(labeled_data[:5])\n",
    "print()\n",
    "print(\"Sentences labeled and converted to dictionary:\")\n",
    "binary_feature_set= [(binary_features(tokenizer.tokenize(tweet)), cat) for (tweet,cat) in labeled_data]\n",
    "print(binary_feature_set[:5])\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "ReadData.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
