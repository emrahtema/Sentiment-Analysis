{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qKr8tClmBvvF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Ncf_h-t0B2Km"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data\\Conf2DataLSTM.txt')\n",
    "data.columns = ['cumle','sinif']\n",
    "data = data[['cumle','sinif']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0reKvMGDH9R2"
   },
   "outputs": [],
   "source": [
    "# Veri setimizin işlenebilmesi için text verileri numaralara çevirmemiz gerekir\n",
    "# Keras bu işlem için hazır bir mekanizma sunmaktadır\n",
    "# Tokenizer sınıfı data içerisinde verilen cümleleri analiz ederek kelimelerin sıklıklarını hesaplar\n",
    "# Parameter: num_words = En sık geçen 25000 kelimeye odaklan, diğerleri önemli değil demek\n",
    "tokenizer = Tokenizer(split=' ',num_words=25000)\n",
    "# Her bir kelimenin sıklığını(frekansını) hesaplar\n",
    "tokenizer.fit_on_texts(data['cumle'].values)\n",
    "# Tüm cümleler tam sayı dizisine dönüştürülür\n",
    "X = tokenizer.texts_to_sequences(data['cumle'].values)\n",
    "# Bütün metinlerimiz 400 sütundan oluşan bir dizi ile temsil edilecek\n",
    "# Çok kısa metinler 0'lar ile doldurulacak, çok uzun metinler ise kesilecek\n",
    "X = pad_sequences(X,maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 937,
     "status": "ok",
     "timestamp": 1525800288690,
     "user": {
      "displayName": "Emrah Tema",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102019531740135725055"
     },
     "user_tz": -180
    },
    "id": "xSPPtGNVIDd9",
    "outputId": "6ded9075-b036-4d34-e3f0-2751953ca39b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yapay sinir ağı modelimiz\n",
    "embed_dim = 128\n",
    "lstm_out = 128\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    # Her bir kelimenin temsil edileceği vektör boyutu. Bu örnek için her bir kelime 128 boyutunda\n",
    "    # bir vektör ile temsil edilir.\n",
    "    model.add(Embedding(25000, embed_dim,input_length = X.shape[1], dropout=0.2))\n",
    "    model.add(LSTM(lstm_out, dropout_U=0.2, dropout_W=0.2))\n",
    "    model.add(Dense(4,activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "  # Çıktılarımızı kategorik hale getirdik (Opsiyonel)\n",
    "Y = pd.get_dummies(data['sinif']).values\n",
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 517821,
     "status": "ok",
     "timestamp": 1525804440484,
     "user": {
      "displayName": "Emrah Tema",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102019531740135725055"
     },
     "user_tz": -180
    },
    "id": "0y9tU9U_IUqN",
    "outputId": "c9e06f88-406d-43e7-e7e9-7d4f83745474"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, dropout=0.2, recurrent_dropout=0.2)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 32s - loss: 1.1436 - acc: 0.5363\n",
      "Epoch 2/5\n",
      " - 34s - loss: 0.3531 - acc: 0.9014\n",
      "Epoch 3/5\n",
      " - 34s - loss: 0.1089 - acc: 0.9714\n",
      "Epoch 4/5\n",
      " - 34s - loss: 0.0558 - acc: 0.9869\n",
      "Epoch 5/5\n",
      " - 34s - loss: 0.0256 - acc: 0.9942\n",
      "score: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Verinin %90'i train, %10'si test verisi olacak şekilde ayrılacak\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.1, random_state = 1)\n",
    "\n",
    "model = build_model()\n",
    "# Oluşturulan model train verileri ile eğitilir\n",
    "# Burada yapay sinir ağını eğitmeye başlıyoruz\n",
    "# nb_epoch: İterasyon sayısı\n",
    "model.fit(X_train, Y_train, nb_epoch = 5, batch_size=32, verbose = 2)\n",
    "# Train verileri ile model eğitildikten sonra test dataları ile doğruluk oranlarına bakılır.\n",
    "score = model.evaluate(X_test, Y_test, verbose = 2)\n",
    "print(\"score: %.2f\" % (score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 844,
     "status": "ok",
     "timestamp": 1525773095097,
     "user": {
      "displayName": "Emrah Tema",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102019531740135725055"
     },
     "user_tz": -180
    },
    "id": "40uzHZ9xIhEm",
    "outputId": "7f23a0f6-cd3c-462b-a6c7-92489b9fbb1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7602026  0.03576458 0.05444506 0.14958785]\n",
      "Kızmak\n"
     ]
    }
   ],
   "source": [
    "# Çıktılarımız => 0: Kızmak, 1: Korkmak, 2: Mutluluk, 3:Üzüntü\n",
    "outputs = [\"Kızmak\", \"Korkmak\", \"Mutluluk\", \"Üzüntü\"]\n",
    "\n",
    "# Verilen örnekler Tokenizer yapısı ile tam sayı dizisine dönüştürülür\n",
    "# Daha sonra eğitilen modele sırayla verilerek anlam analizi sonuçları elde edilir\n",
    "# Her Cümlenin yüzde kaç olumlu ve olumsuz olduğuna dair bilgiler çıktı olarak verilir\n",
    "\n",
    "my_text = [\"çok kız ne kadar ayıp şey\"]\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(my_text)\n",
    "data = pad_sequences(sequences, maxlen=400)\n",
    "predictions = model.predict(data)\n",
    "print(predictions[0])\n",
    "predictions = list(predictions)\n",
    "print(outputs[predictions.index(max(predictions))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BJFzJnVqJ95e"
   },
   "outputs": [],
   "source": [
    "# Burada örnek olarak test edilen cümle, üzerinde doğal dil işleme(NLP) işlemleri uygulanmış bir veridir\n",
    "# Programın amacı analiz olduğundan NLP işlemleri buraya eklenmedi\n",
    "# Eğer yapılmak istenilirse bütün kelimelerin kök halleri alınır"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "LSTM_Test.ipynb adlı dosyanın kopyası",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
